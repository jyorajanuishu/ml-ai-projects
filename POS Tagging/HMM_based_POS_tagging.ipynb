{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains 3 modifications to the Vanilla Viterbi algorithm as follows:\n",
    "* **Transition Based Technique** : This sets the tag of the word based on the maximum of the Transition probabilities.\n",
    "* **Transition and Reverse Transition Based Technique** : This sets the tag of the word based on the maximum of Transition and Reverse Transition probabilities. Reverse Transition probability is probability of t2 given t1 **follows** t2.\n",
    "* **Rule Based Technique** : This sets the tag of the word based on certain rules\n",
    "\n",
    "Some points considered:\n",
    "* Random seeds have been used so that the same test-train split is achieved every time this file is executed\n",
    "* The tag list is sorted so that everytime, the tag for the unknown words is the same\n",
    "* A set of 5 random sentences, again with a random seed, has been considered for evaluating the tag accuracy\n",
    "* The Test_sentences file has been read and 3 relevant sentences have been considered for showing the modification corrections. So if this file is not in the same folder, there will be errors\n",
    "* Manual tagging of the sentences in the Test_sentences has been done and accuracy has been calculated for the same 3 relevant sentences\n",
    "* Conclusions regarding accuracies and modification corrections have been given at the end in a tabular form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint, time\n",
    "import re\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('61', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('will', 'VERB'),\n",
       "  ('join', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('board', 'NOUN'),\n",
       "  ('as', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('Nov.', 'NOUN'),\n",
       "  ('29', 'NUM'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  ('is', 'VERB'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Elsevier', 'NOUN'),\n",
       "  ('N.V.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('Dutch', 'NOUN'),\n",
       "  ('publishing', 'VERB'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Rudolph', 'NOUN'),\n",
       "  ('Agnew', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('55', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('former', 'ADJ'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Consolidated', 'NOUN'),\n",
       "  ('Gold', 'NOUN'),\n",
       "  ('Fields', 'NOUN'),\n",
       "  ('PLC', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('was', 'VERB'),\n",
       "  ('named', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('this', 'DET'),\n",
       "  ('British', 'ADJ'),\n",
       "  ('industrial', 'ADJ'),\n",
       "  ('conglomerate', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('A', 'DET'),\n",
       "  ('form', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('once', 'ADV'),\n",
       "  ('used', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('make', 'VERB'),\n",
       "  ('Kent', 'NOUN'),\n",
       "  ('cigarette', 'NOUN'),\n",
       "  ('filters', 'NOUN'),\n",
       "  ('has', 'VERB'),\n",
       "  ('caused', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('high', 'ADJ'),\n",
       "  ('percentage', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('cancer', 'NOUN'),\n",
       "  ('deaths', 'NOUN'),\n",
       "  ('among', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('workers', 'NOUN'),\n",
       "  ('exposed', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('it', 'PRON'),\n",
       "  ('more', 'ADV'),\n",
       "  ('than', 'ADP'),\n",
       "  ('30', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  (',', '.'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('reported', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('fiber', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('crocidolite', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('is', 'VERB'),\n",
       "  ('unusually', 'ADV'),\n",
       "  ('resilient', 'ADJ'),\n",
       "  ('once', 'ADP'),\n",
       "  ('it', 'PRON'),\n",
       "  ('enters', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('lungs', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('with', 'ADP'),\n",
       "  ('even', 'ADV'),\n",
       "  ('brief', 'ADJ'),\n",
       "  ('exposures', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('it', 'PRON'),\n",
       "  ('causing', 'VERB'),\n",
       "  ('symptoms', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('show', 'VERB'),\n",
       "  ('up', 'PRT'),\n",
       "  ('decades', 'NOUN'),\n",
       "  ('later', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-2', 'X'),\n",
       "  ('.', '.')],\n",
       " [('Lorillard', 'NOUN'),\n",
       "  ('Inc.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('unit', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('New', 'ADJ'),\n",
       "  ('York-based', 'ADJ'),\n",
       "  ('Loews', 'NOUN'),\n",
       "  ('Corp.', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-2', 'X'),\n",
       "  ('makes', 'VERB'),\n",
       "  ('Kent', 'NOUN'),\n",
       "  ('cigarettes', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('stopped', 'VERB'),\n",
       "  ('using', 'VERB'),\n",
       "  ('crocidolite', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('its', 'PRON'),\n",
       "  ('Micronite', 'NOUN'),\n",
       "  ('cigarette', 'NOUN'),\n",
       "  ('filters', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('1956', 'NUM'),\n",
       "  ('.', '.')],\n",
       " [('Although', 'ADP'),\n",
       "  ('preliminary', 'ADJ'),\n",
       "  ('findings', 'NOUN'),\n",
       "  ('were', 'VERB'),\n",
       "  ('reported', 'VERB'),\n",
       "  ('*-2', 'X'),\n",
       "  ('more', 'ADV'),\n",
       "  ('than', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('year', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('latest', 'ADJ'),\n",
       "  ('results', 'NOUN'),\n",
       "  ('appear', 'VERB'),\n",
       "  ('in', 'ADP'),\n",
       "  ('today', 'NOUN'),\n",
       "  (\"'s\", 'PRT'),\n",
       "  ('New', 'NOUN'),\n",
       "  ('England', 'NOUN'),\n",
       "  ('Journal', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Medicine', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('a', 'DET'),\n",
       "  ('forum', 'NOUN'),\n",
       "  ('likely', 'ADJ'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('bring', 'VERB'),\n",
       "  ('new', 'ADJ'),\n",
       "  ('attention', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('the', 'DET'),\n",
       "  ('problem', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('A', 'DET'),\n",
       "  ('Lorillard', 'NOUN'),\n",
       "  ('spokewoman', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  (',', '.'),\n",
       "  ('``', '.'),\n",
       "  ('This', 'DET'),\n",
       "  ('is', 'VERB'),\n",
       "  ('an', 'DET'),\n",
       "  ('old', 'ADJ'),\n",
       "  ('story', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('We', 'PRON'),\n",
       "  (\"'re\", 'VERB'),\n",
       "  ('talking', 'VERB'),\n",
       "  ('about', 'ADP'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  ('before', 'ADP'),\n",
       "  ('anyone', 'NOUN'),\n",
       "  ('heard', 'VERB'),\n",
       "  ('of', 'ADP'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('having', 'VERB'),\n",
       "  ('any', 'DET'),\n",
       "  ('questionable', 'ADJ'),\n",
       "  ('properties', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('There', 'DET'),\n",
       "  ('is', 'VERB'),\n",
       "  ('no', 'DET'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('our', 'PRON'),\n",
       "  ('products', 'NOUN'),\n",
       "  ('now', 'ADV'),\n",
       "  ('.', '.'),\n",
       "  (\"''\", '.')],\n",
       " [('Neither', 'DET'),\n",
       "  ('Lorillard', 'NOUN'),\n",
       "  ('nor', 'CONJ'),\n",
       "  ('the', 'DET'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('who', 'PRON'),\n",
       "  ('*T*-3', 'X'),\n",
       "  ('studied', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('workers', 'NOUN'),\n",
       "  ('were', 'VERB'),\n",
       "  ('aware', 'ADJ'),\n",
       "  ('of', 'ADP'),\n",
       "  ('any', 'DET'),\n",
       "  ('research', 'NOUN'),\n",
       "  ('on', 'ADP'),\n",
       "  ('smokers', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('Kent', 'NOUN'),\n",
       "  ('cigarettes', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('``', '.'),\n",
       "  ('We', 'PRON'),\n",
       "  ('have', 'VERB'),\n",
       "  ('no', 'DET'),\n",
       "  ('useful', 'ADJ'),\n",
       "  ('information', 'NOUN'),\n",
       "  ('on', 'ADP'),\n",
       "  ('whether', 'ADP'),\n",
       "  ('users', 'NOUN'),\n",
       "  ('are', 'VERB'),\n",
       "  ('at', 'ADP'),\n",
       "  ('risk', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  (\"''\", '.'),\n",
       "  ('said', 'VERB'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('James', 'NOUN'),\n",
       "  ('A.', 'NOUN'),\n",
       "  ('Talcott', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Boston', 'NOUN'),\n",
       "  (\"'s\", 'PRT'),\n",
       "  ('Dana-Farber', 'NOUN'),\n",
       "  ('Cancer', 'NOUN'),\n",
       "  ('Institute', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Dr.', 'NOUN'),\n",
       "  ('Talcott', 'NOUN'),\n",
       "  ('led', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('team', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('from', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('National', 'NOUN'),\n",
       "  ('Cancer', 'NOUN'),\n",
       "  ('Institute', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('the', 'DET'),\n",
       "  ('medical', 'ADJ'),\n",
       "  ('schools', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Harvard', 'NOUN'),\n",
       "  ('University', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('Boston', 'NOUN'),\n",
       "  ('University', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('Lorillard', 'NOUN'),\n",
       "  ('spokeswoman', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('was', 'VERB'),\n",
       "  ('used', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('in', 'ADP'),\n",
       "  ('``', '.'),\n",
       "  ('very', 'ADV'),\n",
       "  ('modest', 'ADJ'),\n",
       "  ('amounts', 'NOUN'),\n",
       "  (\"''\", '.'),\n",
       "  ('in', 'ADP'),\n",
       "  ('*', 'X'),\n",
       "  ('making', 'VERB'),\n",
       "  ('paper', 'NOUN'),\n",
       "  ('for', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('filters', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('early', 'ADJ'),\n",
       "  ('1950s', 'NUM'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('replaced', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('with', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('different', 'ADJ'),\n",
       "  ('type', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('filter', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('1956', 'NUM'),\n",
       "  ('.', '.')],\n",
       " [('From', 'ADP'),\n",
       "  ('1953', 'NUM'),\n",
       "  ('to', 'PRT'),\n",
       "  ('1955', 'NUM'),\n",
       "  (',', '.'),\n",
       "  ('9.8', 'NUM'),\n",
       "  ('billion', 'NUM'),\n",
       "  ('Kent', 'NOUN'),\n",
       "  ('cigarettes', 'NOUN'),\n",
       "  ('with', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('filters', 'NOUN'),\n",
       "  ('were', 'VERB'),\n",
       "  ('sold', 'VERB'),\n",
       "  ('*-3', 'X'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('company', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('.', '.')],\n",
       " [('Among', 'ADP'),\n",
       "  ('33', 'NUM'),\n",
       "  ('men', 'NOUN'),\n",
       "  ('who', 'PRON'),\n",
       "  ('*T*-4', 'X'),\n",
       "  ('worked', 'VERB'),\n",
       "  ('closely', 'ADV'),\n",
       "  ('with', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('substance', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('28', 'NUM'),\n",
       "  ('*ICH*-1', 'X'),\n",
       "  ('have', 'VERB'),\n",
       "  ('died', 'VERB'),\n",
       "  ('--', '.'),\n",
       "  ('more', 'ADJ'),\n",
       "  ('than', 'ADP'),\n",
       "  ('three', 'NUM'),\n",
       "  ('times', 'NOUN'),\n",
       "  ('the', 'DET'),\n",
       "  ('expected', 'VERB'),\n",
       "  ('number', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Four', 'NUM'),\n",
       "  ('of', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('five', 'NUM'),\n",
       "  ('surviving', 'VERB'),\n",
       "  ('workers', 'NOUN'),\n",
       "  ('have', 'VERB'),\n",
       "  ('asbestos-related', 'ADJ'),\n",
       "  ('diseases', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('including', 'VERB'),\n",
       "  ('three', 'NUM'),\n",
       "  ('with', 'ADP'),\n",
       "  ('recently', 'ADV'),\n",
       "  ('diagnosed', 'VERB'),\n",
       "  ('cancer', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('total', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('18', 'NUM'),\n",
       "  ('deaths', 'NOUN'),\n",
       "  ('from', 'ADP'),\n",
       "  ('malignant', 'ADJ'),\n",
       "  ('mesothelioma', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('lung', 'NOUN'),\n",
       "  ('cancer', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('asbestosis', 'NOUN'),\n",
       "  ('was', 'VERB'),\n",
       "  ('far', 'ADV'),\n",
       "  ('higher', 'ADJ'),\n",
       "  ('than', 'ADP'),\n",
       "  ('*', 'X'),\n",
       "  ('expected', 'VERB'),\n",
       "  ('*?*', 'X'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('.', '.')],\n",
       " [('``', '.'),\n",
       "  ('The', 'DET'),\n",
       "  ('morbidity', 'NOUN'),\n",
       "  ('rate', 'NOUN'),\n",
       "  ('is', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('striking', 'ADJ'),\n",
       "  ('finding', 'NOUN'),\n",
       "  ('among', 'ADP'),\n",
       "  ('those', 'DET'),\n",
       "  ('of', 'ADP'),\n",
       "  ('us', 'PRON'),\n",
       "  ('who', 'PRON'),\n",
       "  ('*T*-5', 'X'),\n",
       "  ('study', 'VERB'),\n",
       "  ('asbestos-related', 'ADJ'),\n",
       "  ('diseases', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  (\"''\", '.'),\n",
       "  ('said', 'VERB'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('Dr.', 'NOUN'),\n",
       "  ('Talcott', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('percentage', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('lung', 'NOUN'),\n",
       "  ('cancer', 'NOUN'),\n",
       "  ('deaths', 'NOUN'),\n",
       "  ('among', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('workers', 'NOUN'),\n",
       "  ('at', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('West', 'NOUN'),\n",
       "  ('Groton', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('Mass.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('paper', 'NOUN'),\n",
       "  ('factory', 'NOUN'),\n",
       "  ('appears', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('be', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('highest', 'ADJ'),\n",
       "  ('for', 'ADP'),\n",
       "  ('any', 'DET'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('workers', 'NOUN'),\n",
       "  ('studied', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('in', 'ADP'),\n",
       "  ('Western', 'ADJ'),\n",
       "  ('industrialized', 'VERB'),\n",
       "  ('countries', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('he', 'PRON'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-2', 'X'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_data[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tagged sentences in data set = 3914\n",
      "Tagged sentences in training set = 3718\n",
      "Tagged sentences in test set = 196\n"
     ]
    }
   ],
   "source": [
    "#Set random seed to make sure the train and test set are the same each time this call is executed for predictable results\n",
    "train_set, test_set = train_test_split(nltk_data, test_size=0.05, random_state=200)\n",
    "\n",
    "print(\"Total tagged sentences in data set = {0}\".format(len(nltk_data)))\n",
    "print(\"Tagged sentences in training set = {0}\".format(len(train_set)))\n",
    "print(\"Tagged sentences in test set = {0}\".format(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the tagged tuples in the train and the test set\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "test_tagged_words = [tup for sent in test_set for tup in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore train data to see how many unique words and tags are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in train data set = 12076\n",
      "Unique tags in train data set = ['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
      "Number of unique tags in train data set = 12\n"
     ]
    }
   ],
   "source": [
    "# Get the unique tokens/words and unique POS tags in the train set \n",
    "tokens = set([pair[0] for pair in train_tagged_words])\n",
    "\n",
    "# Sort the tag set so that later on, the Viterbi algorithm always picks up the same first tag for unknown words. \n",
    "# Else the accuracy keeps changing\n",
    "tags = sorted(set([pair[1] for pair in train_tagged_words]))\n",
    "\n",
    "no_of_unique_tokens = len(tokens)\n",
    "no_of_unique_tags = len(tags)\n",
    "\n",
    "#print(\"Unique words in data set = {0}\".format(tokens))\n",
    "print(\"Number of unique words in train data set = {0}\".format(no_of_unique_tokens))\n",
    "print(\"Unique tags in train data set = {0}\".format(tags))\n",
    "print(\"Number of unique tags in train data set = {0}\".format(no_of_unique_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Emission and Transition Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "def t2_given_t1Precedes(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "tags_matrix = np.zeros((no_of_unique_tags, no_of_unique_tags), dtype='float32')\n",
    "for i, t1 in enumerate(tags):\n",
    "    for j, t2 in enumerate(tags):\n",
    "        t2_given_t1Results = t2_given_t1Precedes(t2, t1)\n",
    "        tags_matrix[i, j] = t2_given_t1Results[0]/t2_given_t1Results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.092866</td>\n",
       "      <td>0.044406</td>\n",
       "      <td>0.090344</td>\n",
       "      <td>0.052243</td>\n",
       "      <td>0.058458</td>\n",
       "      <td>0.174293</td>\n",
       "      <td>0.222032</td>\n",
       "      <td>0.080886</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.089173</td>\n",
       "      <td>0.027202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.064929</td>\n",
       "      <td>0.067388</td>\n",
       "      <td>0.078210</td>\n",
       "      <td>0.004427</td>\n",
       "      <td>0.016560</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.698639</td>\n",
       "      <td>0.019839</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.010985</td>\n",
       "      <td>0.012461</td>\n",
       "      <td>0.020823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.039804</td>\n",
       "      <td>0.106499</td>\n",
       "      <td>0.016967</td>\n",
       "      <td>0.013232</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.323872</td>\n",
       "      <td>0.323445</td>\n",
       "      <td>0.063067</td>\n",
       "      <td>0.068082</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.008324</td>\n",
       "      <td>0.034361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.135610</td>\n",
       "      <td>0.130305</td>\n",
       "      <td>0.118700</td>\n",
       "      <td>0.078581</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>0.032825</td>\n",
       "      <td>0.015915</td>\n",
       "      <td>0.014257</td>\n",
       "      <td>0.345822</td>\n",
       "      <td>0.022215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.034451</td>\n",
       "      <td>0.119181</td>\n",
       "      <td>0.053073</td>\n",
       "      <td>0.055866</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.119181</td>\n",
       "      <td>0.350093</td>\n",
       "      <td>0.041899</td>\n",
       "      <td>0.056797</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>0.155028</td>\n",
       "      <td>0.008845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.017125</td>\n",
       "      <td>0.204896</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>0.013025</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.637603</td>\n",
       "      <td>0.022552</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.039797</td>\n",
       "      <td>0.046069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.239953</td>\n",
       "      <td>0.012096</td>\n",
       "      <td>0.176595</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.042445</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>0.264145</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.044304</td>\n",
       "      <td>0.147229</td>\n",
       "      <td>0.028710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.115852</td>\n",
       "      <td>0.033185</td>\n",
       "      <td>0.035852</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.353778</td>\n",
       "      <td>0.183704</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.027556</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>0.210370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.039330</td>\n",
       "      <td>0.074377</td>\n",
       "      <td>0.023364</td>\n",
       "      <td>0.034657</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.204829</td>\n",
       "      <td>0.007788</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.012461</td>\n",
       "      <td>0.486371</td>\n",
       "      <td>0.093458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.041585</td>\n",
       "      <td>0.087099</td>\n",
       "      <td>0.020629</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.102161</td>\n",
       "      <td>0.250164</td>\n",
       "      <td>0.057629</td>\n",
       "      <td>0.018337</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.395219</td>\n",
       "      <td>0.012770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.034714</td>\n",
       "      <td>0.065691</td>\n",
       "      <td>0.092154</td>\n",
       "      <td>0.082503</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.133873</td>\n",
       "      <td>0.111924</td>\n",
       "      <td>0.022961</td>\n",
       "      <td>0.034791</td>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.167964</td>\n",
       "      <td>0.216687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.164213</td>\n",
       "      <td>0.016645</td>\n",
       "      <td>0.145166</td>\n",
       "      <td>0.026569</td>\n",
       "      <td>0.010083</td>\n",
       "      <td>0.055058</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.054898</td>\n",
       "      <td>0.182298</td>\n",
       "      <td>0.205346</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .       ADJ       ADP       ADV      CONJ       DET      NOUN  \\\n",
       ".     0.092866  0.044406  0.090344  0.052243  0.058458  0.174293  0.222032   \n",
       "ADJ   0.064929  0.067388  0.078210  0.004427  0.016560  0.005083  0.698639   \n",
       "ADP   0.039804  0.106499  0.016967  0.013232  0.000854  0.323872  0.323445   \n",
       "ADV   0.135610  0.130305  0.118700  0.078581  0.006631  0.068966  0.030172   \n",
       "CONJ  0.034451  0.119181  0.053073  0.055866  0.000466  0.119181  0.350093   \n",
       "DET   0.017125  0.204896  0.009407  0.013025  0.000482  0.005548  0.637603   \n",
       "NOUN  0.239953  0.012096  0.176595  0.016905  0.042445  0.013408  0.264145   \n",
       "NUM   0.115852  0.033185  0.035852  0.002963  0.013926  0.003556  0.353778   \n",
       "PRON  0.039330  0.074377  0.023364  0.034657  0.005452  0.009735  0.204829   \n",
       "PRT   0.041585  0.087099  0.020629  0.010151  0.002292  0.102161  0.250164   \n",
       "VERB  0.034714  0.065691  0.092154  0.082503  0.005293  0.133873  0.111924   \n",
       "X     0.164213  0.016645  0.145166  0.026569  0.010083  0.055058  0.062100   \n",
       "\n",
       "           NUM      PRON       PRT      VERB         X  \n",
       ".     0.080886  0.065574  0.002432  0.089173  0.027202  \n",
       "ADJ   0.019839  0.000656  0.010985  0.012461  0.020823  \n",
       "ADP   0.063067  0.068082  0.001494  0.008324  0.034361  \n",
       "ADV   0.032825  0.015915  0.014257  0.345822  0.022215  \n",
       "CONJ  0.041899  0.056797  0.005121  0.155028  0.008845  \n",
       "DET   0.022552  0.003256  0.000241  0.039797  0.046069  \n",
       "NOUN  0.009509  0.004700  0.044304  0.147229  0.028710  \n",
       "NUM   0.183704  0.001481  0.027556  0.017778  0.210370  \n",
       "PRON  0.007788  0.008178  0.012461  0.486371  0.093458  \n",
       "PRT   0.057629  0.018337  0.001965  0.395219  0.012770  \n",
       "VERB  0.022961  0.034791  0.031445  0.167964  0.216687  \n",
       "X     0.002721  0.054898  0.182298  0.205346  0.074904  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = tags, index=tags)\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi_Vanilla(words, T = tags):\n",
    "    state = []\n",
    "    unknown_word_tags = []\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            word_given_tagResults = word_given_tag(words[key], tag)\n",
    "            emission_p = word_given_tagResults[0]/word_given_tagResults[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)        \n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "        if pmax == 0:\n",
    "            unknown_word_tags.append((word, state_max))\n",
    "    return list(zip(words, state)), unknown_word_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: A transition probability based approach\n",
    "\n",
    "This flavour considers the maximum of transition probability for tagging the unknown words.\n",
    "<p>Steps:\n",
    "* Both Emission and Transition probability is calculated for a word\n",
    "* If a word has the max probability as 0, this means that the Emission probability is 0 because none of the Transition probabilities are 0 as per the tags-matrix. Effectively, the word is unknown.\n",
    "* In this case, tag having the maximum Transition probability is considered as the POS tag for the unknown word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Viterbi_TransitionBased(words, T = tags):\n",
    "    state = []\n",
    "    unknown_word_tags = []\n",
    "    #T = sorted(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        trans_probs = []\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities            \n",
    "            word_given_tagResults = word_given_tag(words[key], tag)\n",
    "            emission_p = word_given_tagResults[0]/word_given_tagResults[1]\n",
    "            state_probability = emission_p * transition_p\n",
    "            #Cache the transition probabilities also\n",
    "            trans_probs.append(transition_p)\n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        tmax = max(trans_probs)\n",
    "        if pmax > 0:\n",
    "        # getting state for which probability is maximum\n",
    "            state_max = T[p.index(pmax)] \n",
    "        else:\n",
    "            state_max = T[trans_probs.index(tmax)] \n",
    "            unknown_word_tags.append((word,state_max))\n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state)), unknown_word_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Another transition probability based approach\n",
    "\n",
    "The Transition probability considers the probability of a **tag given a previous tag**. This is another flavour which considers the probability of a **tag given a following tag** also.\n",
    "Maximum of transition probabilities and reverse transition probabilities is considered here for tagging the unknown words.\n",
    "<p>Steps:\n",
    "* Both Emission and Transition probability is calculated for a word\n",
    "* If a word has the max probability as 0, this means that the Emission probability is 0 because none of the Transition probabilities are 0 as per the tags-matrix. Effectively, the word is unknown.\n",
    "* After this the words are scanned again(disadvantage, but this method depends on knowing the next tag) and the probabilities are calculated for a tag given a following tag. Maximum of these is taken as the tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), where t2 is followed by t1 i.e. Reverse Transition Probability\n",
    "def t2_given_t1Follows(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index+1]==t1 and tags[index] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rev_tags_matrix = np.zeros((no_of_unique_tags, no_of_unique_tags), dtype='float32')\n",
    "for i, t1 in enumerate(tags):\n",
    "    for j, t2 in enumerate(tags): \n",
    "        t2_given_t1FollowsResult = t2_given_t1Follows(t2, t1)\n",
    "        rev_tags_matrix[i, j] = t2_given_t1FollowsResult[0]/t2_given_t1FollowsResult[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.092866</td>\n",
       "      <td>0.035669</td>\n",
       "      <td>0.033598</td>\n",
       "      <td>0.036840</td>\n",
       "      <td>0.006665</td>\n",
       "      <td>0.012790</td>\n",
       "      <td>0.593226</td>\n",
       "      <td>0.035219</td>\n",
       "      <td>0.009097</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>0.040173</td>\n",
       "      <td>0.092416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.080833</td>\n",
       "      <td>0.067388</td>\n",
       "      <td>0.163633</td>\n",
       "      <td>0.064437</td>\n",
       "      <td>0.041974</td>\n",
       "      <td>0.278570</td>\n",
       "      <td>0.054435</td>\n",
       "      <td>0.018364</td>\n",
       "      <td>0.031317</td>\n",
       "      <td>0.043614</td>\n",
       "      <td>0.138383</td>\n",
       "      <td>0.017052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.107032</td>\n",
       "      <td>0.050902</td>\n",
       "      <td>0.016967</td>\n",
       "      <td>0.038203</td>\n",
       "      <td>0.012165</td>\n",
       "      <td>0.008324</td>\n",
       "      <td>0.517234</td>\n",
       "      <td>0.012912</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.126347</td>\n",
       "      <td>0.096788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.008952</td>\n",
       "      <td>0.041114</td>\n",
       "      <td>0.078581</td>\n",
       "      <td>0.039788</td>\n",
       "      <td>0.035809</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>0.029509</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.351459</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.302142</td>\n",
       "      <td>0.047020</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.009311</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.542365</td>\n",
       "      <td>0.021881</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.031657</td>\n",
       "      <td>0.029330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.233357</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>0.366015</td>\n",
       "      <td>0.025084</td>\n",
       "      <td>0.030873</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.044380</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.037627</td>\n",
       "      <td>0.207429</td>\n",
       "      <td>0.041486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.089809</td>\n",
       "      <td>0.155245</td>\n",
       "      <td>0.110431</td>\n",
       "      <td>0.003315</td>\n",
       "      <td>0.027398</td>\n",
       "      <td>0.192626</td>\n",
       "      <td>0.264145</td>\n",
       "      <td>0.043502</td>\n",
       "      <td>0.019164</td>\n",
       "      <td>0.027835</td>\n",
       "      <td>0.052392</td>\n",
       "      <td>0.014136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.266074</td>\n",
       "      <td>0.035852</td>\n",
       "      <td>0.175111</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.055407</td>\n",
       "      <td>0.077333</td>\n",
       "      <td>0.183704</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>0.052148</td>\n",
       "      <td>0.087407</td>\n",
       "      <td>0.005037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.283489</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.248442</td>\n",
       "      <td>0.018692</td>\n",
       "      <td>0.047508</td>\n",
       "      <td>0.010514</td>\n",
       "      <td>0.050234</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.021807</td>\n",
       "      <td>0.174065</td>\n",
       "      <td>0.133567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.008841</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.014080</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.398166</td>\n",
       "      <td>0.030452</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.132286</td>\n",
       "      <td>0.372954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.077055</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.081180</td>\n",
       "      <td>0.025918</td>\n",
       "      <td>0.025685</td>\n",
       "      <td>0.314524</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>0.097214</td>\n",
       "      <td>0.093945</td>\n",
       "      <td>0.167964</td>\n",
       "      <td>0.099860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.048335</td>\n",
       "      <td>0.020327</td>\n",
       "      <td>0.051536</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>0.126120</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.038412</td>\n",
       "      <td>0.006242</td>\n",
       "      <td>0.445583</td>\n",
       "      <td>0.074904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .       ADJ       ADP       ADV      CONJ       DET      NOUN  \\\n",
       ".     0.092866  0.035669  0.033598  0.036840  0.006665  0.012790  0.593226   \n",
       "ADJ   0.080833  0.067388  0.163633  0.064437  0.041974  0.278570  0.054435   \n",
       "ADP   0.107032  0.050902  0.016967  0.038203  0.012165  0.008324  0.517234   \n",
       "ADV   0.192308  0.008952  0.041114  0.078581  0.039788  0.035809  0.153846   \n",
       "CONJ  0.302142  0.047020  0.003724  0.009311  0.000466  0.001862  0.542365   \n",
       "DET   0.233357  0.003739  0.366015  0.025084  0.030873  0.005548  0.044380   \n",
       "NOUN  0.089809  0.155245  0.110431  0.003315  0.027398  0.192626  0.264145   \n",
       "NUM   0.266074  0.035852  0.175111  0.029333  0.026667  0.055407  0.077333   \n",
       "PRON  0.283489  0.001558  0.248442  0.018692  0.047508  0.010514  0.050234   \n",
       "PRT   0.008841  0.021938  0.004584  0.014080  0.003602  0.000655  0.398166   \n",
       "VERB  0.077055  0.005915  0.006071  0.081180  0.025918  0.025685  0.314524   \n",
       "X     0.048335  0.020327  0.051536  0.010723  0.003041  0.061140  0.126120   \n",
       "\n",
       "           NUM      PRON       PRT      VERB         X  \n",
       ".     0.035219  0.009097  0.011439  0.040173  0.092416  \n",
       "ADJ   0.018364  0.031317  0.043614  0.138383  0.017052  \n",
       "ADP   0.012912  0.006403  0.006723  0.126347  0.096788  \n",
       "ADV   0.003316  0.029509  0.010279  0.351459  0.055040  \n",
       "CONJ  0.021881  0.006518  0.003259  0.031657  0.029330  \n",
       "DET   0.001447  0.003015  0.037627  0.207429  0.041486  \n",
       "NOUN  0.043502  0.019164  0.027835  0.052392  0.014136  \n",
       "NUM   0.183704  0.005926  0.052148  0.087407  0.005037  \n",
       "PRON  0.001947  0.008178  0.021807  0.174065  0.133567  \n",
       "PRT   0.030452  0.010478  0.001965  0.132286  0.372954  \n",
       "VERB  0.004670  0.097214  0.093945  0.167964  0.099860  \n",
       "X     0.113636  0.038412  0.006242  0.445583  0.074904  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "rev_tags_df = pd.DataFrame(rev_tags_matrix, columns = tags, index=tags)\n",
    "rev_tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting this to False for now to restrict some of the verbose information \n",
    "#about Transition Probability and Reverse Transition Probability\n",
    "#Can be set to true later if required\n",
    "print_tag_prob_comp = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Viterbi_TransitionBasedRev(words, T = tags):\n",
    "    state = []\n",
    "    unknown_word_tags = []\n",
    "    max_probs = [] \n",
    "    max_trans_probs = []\n",
    "    max_trans_probs_tuple = []\n",
    "    trans_tags = []\n",
    "    trans_prob_comparison = []\n",
    "    #T = sorted(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        trans_probs = []\n",
    "        trans_prob_tuple = []\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities            \n",
    "            word_given_tagResults = word_given_tag(words[key], tag)\n",
    "            emission_p = word_given_tagResults[0]/word_given_tagResults[1]\n",
    "            state_probability = emission_p * transition_p\n",
    "            trans_probs.append(transition_p)\n",
    "            if key == 0:\n",
    "                trans_prob_tuple.append('{0} followed by {1} with prob = {2}'.format('.', tag, transition_p))\n",
    "            else:\n",
    "                trans_prob_tuple.append('{0} followed by {1} with prob = {2}'.format(state[-1], tag, transition_p))\n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        tmax = max(trans_probs)\n",
    "        max_probs.append(pmax)\n",
    "        max_trans_probs.append(tmax)\n",
    "        trans_tags.append(T[trans_probs.index(tmax)])\n",
    "        max_trans_probs_tuple.append(trans_prob_tuple[trans_probs.index(tmax)])\n",
    "        state_max = T[p.index(pmax)]        \n",
    "        state.append(state_max)\n",
    "    \n",
    "    for i, maxprob in enumerate(max_probs):\n",
    "        if maxprob == 0: \n",
    "            rev_tag_probs = []\n",
    "            rev_trans_prob_tuple = []\n",
    "            for tag in T:\n",
    "                transition_p = rev_tags_df.loc[state[i+1], tag]\n",
    "                rev_tag_probs.append(transition_p)\n",
    "                rev_trans_prob_tuple.append('{0} followed by {1} with prob = {2}'.format(tag, state[i+1], transition_p))\n",
    "            inv_tmax = max(rev_tag_probs) \n",
    "            if inv_tmax > max_trans_probs[i]:                \n",
    "                state[i] = T[rev_tag_probs.index(inv_tmax)]                \n",
    "            else:  \n",
    "                state[i] = trans_tags[i]\n",
    "            trans_prob_comparison.append((words[i], max_trans_probs_tuple[i], \n",
    "                            rev_trans_prob_tuple[rev_tag_probs.index(inv_tmax)], 'Applying {0}'.format(state[i])))    \n",
    "            unknown_word_tags.append((words[i],state[i]))\n",
    "    if print_tag_prob_comp: \n",
    "        print(\"Tag Applied with Probability comparisons = \", trans_prob_comparison)\n",
    "        print(\"\")\n",
    "    return list(zip(words, state)), unknown_word_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 3: A rule based approach\n",
    "\n",
    "Another set of modifications to the Vanilla Viterbi algorithm where it applies some rules for tagging the unknown words\n",
    "The rules are applied in the following order:\n",
    "* Rule 1: All words having one or more digits are tagged as NUM\n",
    "* Rule 2: All words starting with one or more star are tagged as X \n",
    "* Rule 3: All words starting with numbers and ending with st,nd,rd,th are tagged as ADJ\n",
    "* Rule 4: All words starting with caps in the middle of a sentence are tagged as NOUN\n",
    "<p>The next 4 rules are taken from https://dictionary.cambridge.org/grammar/british-grammar/word-formation/suffixes\n",
    "* Rule 5: All words ending with ly|wards|wise are tagged as ADV\n",
    "* Rule 6: All words ending with ate|en|ify|ise|ize|ed|ing are tagged as VERB\n",
    "* Rule 7: All words ending with able|ible|al|en|ese|ful|i|ic|ish|ive|ian|less|ous are tagged as ADJ\n",
    "* Rule 8: All words ending with age|al|ance|ence|dom|ee|er|or|hood|ism|ist|ity|ty|ment|ness|ry|ship|sion|tion|xion are tagged as NOUN\n",
    "* Rule 8: If a word does not belong to any of the above rules, then it probably is some Name and hence default tagging done is a NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_RuleBased(words, T = tags):\n",
    "    state = []\n",
    "    unknown_word_tags = []\n",
    "    #T = sorted(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc[tag, '.']\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            word_given_tagResults = word_given_tag(words[key], tag)\n",
    "            emission_p = word_given_tagResults[0]/word_given_tagResults[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p) \n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)]\n",
    "        if pmax == 0:            \n",
    "            if re.match('^(\\d)[0-9.]+(\\d)$', word):\n",
    "                state_max = 'NUM' \n",
    "            elif re.match('^\\*+.*', word):\n",
    "                state_max = 'X'\n",
    "            elif re.match('^(\\d)[0-9]+(st|nd|rd|th)$',word):\n",
    "                state_max = 'ADJ'\n",
    "            elif word[0].isupper() and words[key-1] != '.':\n",
    "                state_max = 'NOUN'    \n",
    "            elif re.match('.+(ly|wards|wise)$', word):\n",
    "                state_max = 'ADV'\n",
    "            elif re.match('.+(ate|en|ify|ise|ize|ed|ing)$', word):\n",
    "                state_max = 'VERB' \n",
    "            elif re.match('.+(able|ible|al|en|ese|ful|i|ic|ish|ive|ian|less|ous)$', word):\n",
    "                state_max = 'ADJ'\n",
    "            elif re.match('.+(age|al|ance|ence|dom|ee|er|or|hood|ism|ist|ity|ty|ment|ness|ry|ship|sion|tion|xion)$', word):\n",
    "                state_max = 'NOUN'                           \n",
    "            else: \n",
    "                state_max = 'NOUN'                \n",
    "            unknown_word_tags.append((word, state_max))          \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state)), unknown_word_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function defined to set up the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_test_data(test_set, no_of_sent):\n",
    "    random.seed(1234)\n",
    "    # choose random 5 sents\n",
    "    rndom = [random.randint(1,len(test_set)) for x in range(no_of_sent)]\n",
    "    # list of sents\n",
    "    test_run = [test_set[i] for i in rndom]\n",
    "    # list of tagged words\n",
    "    test_run_base = [tup for sent in test_run for tup in sent]\n",
    "    # list of untagged words\n",
    "    test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "    return test_run, test_tagged_words, test_run_base  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function defined to:\n",
    "* Perform tagging by calling the passed algorithm - A function reference is passed as parameter here\n",
    "* Record the time taken in seconds\n",
    "* Conditionally calculate the accuracy based on whether a test_run_base with tagged words is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_input_words(fn, test_tagged_words, test_run_base = None):\n",
    "    start = time.time()\n",
    "    tagged_seq, unknown_word_tags = fn(test_tagged_words)\n",
    "    end = time.time()\n",
    "    difference = end-start\n",
    "\n",
    "    # accuracy\n",
    "    accuracy = None\n",
    "    if test_run_base !=  None:\n",
    "        check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "        accuracy = len(check)/len(tagged_seq)\n",
    "    \n",
    "    return accuracy, difference, unknown_word_tags, tagged_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``',\n",
       " 'The',\n",
       " 'disturbing',\n",
       " 'thing',\n",
       " 'about',\n",
       " 'this',\n",
       " 'abortion',\n",
       " 'issue',\n",
       " 'is',\n",
       " 'that',\n",
       " 'the',\n",
       " 'debate',\n",
       " 'has',\n",
       " 'become',\n",
       " 'polarized',\n",
       " '*-1',\n",
       " ',',\n",
       " 'so',\n",
       " 'that',\n",
       " 'no',\n",
       " 'mechanism',\n",
       " '*ICH*-2',\n",
       " 'exists',\n",
       " \"''\",\n",
       " 'for',\n",
       " '*',\n",
       " 'finding',\n",
       " 'a',\n",
       " 'middle',\n",
       " 'ground',\n",
       " '.',\n",
       " 'The',\n",
       " 'judge',\n",
       " 'declined',\n",
       " '*-1',\n",
       " 'to',\n",
       " 'discuss',\n",
       " 'his',\n",
       " 'salary',\n",
       " 'in',\n",
       " 'detail',\n",
       " ',',\n",
       " 'but',\n",
       " 'said',\n",
       " ':',\n",
       " '``',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'going',\n",
       " '*-2',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'high-priced',\n",
       " 'lawyer',\n",
       " '.',\n",
       " \"''\",\n",
       " 'The',\n",
       " 'Japanese',\n",
       " 'retort',\n",
       " 'that',\n",
       " 'the',\n",
       " 'first',\n",
       " 'round',\n",
       " 'was',\n",
       " 'too',\n",
       " 'early',\n",
       " '*',\n",
       " 'to',\n",
       " 'make',\n",
       " 'concessions',\n",
       " '.',\n",
       " '``',\n",
       " 'This',\n",
       " 'conforms',\n",
       " 'to',\n",
       " 'the',\n",
       " '`',\n",
       " 'soft',\n",
       " 'landing',\n",
       " \"'\",\n",
       " 'scenario',\n",
       " ',',\n",
       " \"''\",\n",
       " 'said',\n",
       " '*T*-1',\n",
       " 'Elliott',\n",
       " 'Platt',\n",
       " ',',\n",
       " 'an',\n",
       " 'economist',\n",
       " 'at',\n",
       " 'Donaldson',\n",
       " ',',\n",
       " 'Lufkin',\n",
       " '&',\n",
       " 'Jenrette',\n",
       " 'Securities',\n",
       " 'Corp',\n",
       " '.',\n",
       " 'In',\n",
       " 'its',\n",
       " 'construction',\n",
       " 'spending',\n",
       " 'report',\n",
       " ',',\n",
       " 'the',\n",
       " 'Commerce',\n",
       " 'Department',\n",
       " 'said',\n",
       " '0',\n",
       " 'residential',\n",
       " 'construction',\n",
       " ',',\n",
       " 'which',\n",
       " '*T*-50',\n",
       " 'accounts',\n",
       " 'for',\n",
       " 'nearly',\n",
       " 'half',\n",
       " 'of',\n",
       " 'all',\n",
       " 'construction',\n",
       " 'spending',\n",
       " ',',\n",
       " 'was',\n",
       " 'off',\n",
       " '0.9',\n",
       " '%',\n",
       " '*ICH*-3',\n",
       " 'in',\n",
       " 'September',\n",
       " 'to',\n",
       " 'an',\n",
       " 'annual',\n",
       " 'rate',\n",
       " 'of',\n",
       " '$',\n",
       " '191.9',\n",
       " 'billion',\n",
       " '*U*',\n",
       " '.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running on entire test dataset would take more than 3-4hrs. \n",
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "test_run, test_tagged_words, test_run_base = setup_test_data(test_set, 5)\n",
    "test_tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viterbi Vanilla Results=========================>\n",
      "\n",
      "Accuracy =  0.89\n",
      "\n",
      "Time Taken in seconds =  13.7\n",
      "\n",
      "Unknown word tags =  [('polarized', '.'), ('exists', '.'), ('detail', '.'), ('retort', '.'), ('concessions', '.'), ('conforms', '.'), ('Elliott', '.'), ('191.9', '.')]\n",
      "\n",
      "Final tagging result =  [('``', '.'), ('The', 'DET'), ('disturbing', 'ADJ'), ('thing', 'NOUN'), ('about', 'ADP'), ('this', 'DET'), ('abortion', 'NOUN'), ('issue', 'NOUN'), ('is', 'VERB'), ('that', 'ADP'), ('the', 'DET'), ('debate', 'NOUN'), ('has', 'VERB'), ('become', 'VERB'), ('polarized', '.'), ('*-1', 'X'), (',', '.'), ('so', 'ADV'), ('that', 'ADP'), ('no', 'DET'), ('mechanism', 'NOUN'), ('*ICH*-2', 'X'), ('exists', '.'), (\"''\", '.'), ('for', 'ADP'), ('*', 'X'), ('finding', 'VERB'), ('a', 'DET'), ('middle', 'NOUN'), ('ground', 'NOUN'), ('.', '.'), ('The', 'DET'), ('judge', 'NOUN'), ('declined', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('discuss', 'VERB'), ('his', 'PRON'), ('salary', 'NOUN'), ('in', 'ADP'), ('detail', '.'), (',', '.'), ('but', 'CONJ'), ('said', 'VERB'), (':', '.'), ('``', '.'), ('I', 'PRON'), (\"'m\", 'VERB'), ('going', 'VERB'), ('*-2', 'X'), ('to', 'PRT'), ('be', 'VERB'), ('a', 'DET'), ('high-priced', 'ADJ'), ('lawyer', 'NOUN'), ('.', '.'), (\"''\", '.'), ('The', 'DET'), ('Japanese', 'ADJ'), ('retort', '.'), ('that', 'DET'), ('the', 'DET'), ('first', 'ADJ'), ('round', 'NOUN'), ('was', 'VERB'), ('too', 'ADV'), ('early', 'ADJ'), ('*', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('concessions', '.'), ('.', '.'), ('``', '.'), ('This', 'DET'), ('conforms', '.'), ('to', 'PRT'), ('the', 'DET'), ('`', '.'), ('soft', 'ADJ'), ('landing', 'NOUN'), (\"'\", 'PRT'), ('scenario', 'NOUN'), (',', '.'), (\"''\", '.'), ('said', 'VERB'), ('*T*-1', 'X'), ('Elliott', '.'), ('Platt', 'NOUN'), (',', '.'), ('an', 'DET'), ('economist', 'NOUN'), ('at', 'ADP'), ('Donaldson', 'NOUN'), (',', '.'), ('Lufkin', 'NOUN'), ('&', 'CONJ'), ('Jenrette', 'NOUN'), ('Securities', 'NOUN'), ('Corp', 'NOUN'), ('.', '.'), ('In', 'ADP'), ('its', 'PRON'), ('construction', 'NOUN'), ('spending', 'NOUN'), ('report', 'NOUN'), (',', '.'), ('the', 'DET'), ('Commerce', 'NOUN'), ('Department', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('residential', 'ADJ'), ('construction', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-50', 'X'), ('accounts', 'NOUN'), ('for', 'ADP'), ('nearly', 'ADV'), ('half', 'DET'), ('of', 'ADP'), ('all', 'DET'), ('construction', 'NOUN'), ('spending', 'NOUN'), (',', '.'), ('was', 'VERB'), ('off', 'PRT'), ('0.9', 'NUM'), ('%', 'NOUN'), ('*ICH*-3', 'X'), ('in', 'ADP'), ('September', 'NOUN'), ('to', 'PRT'), ('an', 'DET'), ('annual', 'ADJ'), ('rate', 'NOUN'), ('of', 'ADP'), ('$', '.'), ('191.9', '.'), ('billion', 'NUM'), ('*U*', 'X'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "accuracy, difference, unknown_word_tags, tagged_seq = tag_input_words(Viterbi_Vanilla, test_tagged_words, test_run_base)\n",
    "print('Viterbi Vanilla Results=========================>')\n",
    "print(\"\")\n",
    "print(\"Accuracy = \", round(accuracy,2))\n",
    "print(\"\")\n",
    "print(\"Time Taken in seconds = \", round(difference,2))\n",
    "print(\"\")\n",
    "print(\"Unknown word tags = \", unknown_word_tags)\n",
    "print(\"\")\n",
    "print(\"Final tagging result = \", tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viterbi Plain with Transition Based Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.91\n",
      "\n",
      "Time Taken in seconds =  13.12\n",
      "\n",
      "Unknown word tags =  [('polarized', 'X'), ('exists', 'VERB'), ('detail', 'DET'), ('retort', 'NOUN'), ('concessions', 'X'), ('conforms', 'NOUN'), ('Elliott', 'VERB'), ('191.9', 'NOUN')]\n",
      "\n",
      "Final tagging result =  [('``', '.'), ('The', 'DET'), ('disturbing', 'ADJ'), ('thing', 'NOUN'), ('about', 'ADP'), ('this', 'DET'), ('abortion', 'NOUN'), ('issue', 'NOUN'), ('is', 'VERB'), ('that', 'ADP'), ('the', 'DET'), ('debate', 'NOUN'), ('has', 'VERB'), ('become', 'VERB'), ('polarized', 'X'), ('*-1', 'X'), (',', '.'), ('so', 'ADV'), ('that', 'ADP'), ('no', 'DET'), ('mechanism', 'NOUN'), ('*ICH*-2', 'X'), ('exists', 'VERB'), (\"''\", '.'), ('for', 'ADP'), ('*', 'X'), ('finding', 'VERB'), ('a', 'DET'), ('middle', 'NOUN'), ('ground', 'NOUN'), ('.', '.'), ('The', 'DET'), ('judge', 'NOUN'), ('declined', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('discuss', 'VERB'), ('his', 'PRON'), ('salary', 'NOUN'), ('in', 'ADP'), ('detail', 'DET'), (',', '.'), ('but', 'CONJ'), ('said', 'VERB'), (':', '.'), ('``', '.'), ('I', 'PRON'), (\"'m\", 'VERB'), ('going', 'VERB'), ('*-2', 'X'), ('to', 'PRT'), ('be', 'VERB'), ('a', 'DET'), ('high-priced', 'ADJ'), ('lawyer', 'NOUN'), ('.', '.'), (\"''\", '.'), ('The', 'DET'), ('Japanese', 'ADJ'), ('retort', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('first', 'ADJ'), ('round', 'NOUN'), ('was', 'VERB'), ('too', 'ADV'), ('early', 'ADJ'), ('*', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('concessions', 'X'), ('.', '.'), ('``', '.'), ('This', 'DET'), ('conforms', 'NOUN'), ('to', 'PRT'), ('the', 'DET'), ('`', '.'), ('soft', 'ADJ'), ('landing', 'NOUN'), (\"'\", 'PRT'), ('scenario', 'NOUN'), (',', '.'), (\"''\", '.'), ('said', 'VERB'), ('*T*-1', 'X'), ('Elliott', 'VERB'), ('Platt', 'NOUN'), (',', '.'), ('an', 'DET'), ('economist', 'NOUN'), ('at', 'ADP'), ('Donaldson', 'NOUN'), (',', '.'), ('Lufkin', 'NOUN'), ('&', 'CONJ'), ('Jenrette', 'NOUN'), ('Securities', 'NOUN'), ('Corp', 'NOUN'), ('.', '.'), ('In', 'ADP'), ('its', 'PRON'), ('construction', 'NOUN'), ('spending', 'NOUN'), ('report', 'NOUN'), (',', '.'), ('the', 'DET'), ('Commerce', 'NOUN'), ('Department', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('residential', 'ADJ'), ('construction', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-50', 'X'), ('accounts', 'NOUN'), ('for', 'ADP'), ('nearly', 'ADV'), ('half', 'DET'), ('of', 'ADP'), ('all', 'DET'), ('construction', 'NOUN'), ('spending', 'NOUN'), (',', '.'), ('was', 'VERB'), ('off', 'PRT'), ('0.9', 'NUM'), ('%', 'NOUN'), ('*ICH*-3', 'X'), ('in', 'ADP'), ('September', 'NOUN'), ('to', 'PRT'), ('an', 'DET'), ('annual', 'ADJ'), ('rate', 'NOUN'), ('of', 'ADP'), ('$', '.'), ('191.9', 'NOUN'), ('billion', 'NUM'), ('*U*', 'X'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "accuracy, difference, unknown_word_tags, tagged_seq = tag_input_words(Viterbi_TransitionBased, test_tagged_words, test_run_base)\n",
    "print(\"Accuracy = \", round(accuracy,2))\n",
    "print(\"\")\n",
    "print(\"Time Taken in seconds = \", round(difference,2))\n",
    "print(\"\")\n",
    "print(\"Unknown word tags = \", unknown_word_tags)\n",
    "print(\"\")\n",
    "print(\"Final tagging result = \", tagged_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viterbi Plain with Reverse Transition Based Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.92\n",
      "\n",
      "Time Taken in seconds =  13.02\n",
      "\n",
      "Unknown word tags =  [('polarized', 'VERB'), ('exists', 'NOUN'), ('detail', 'NOUN'), ('retort', 'NOUN'), ('concessions', 'NOUN'), ('conforms', 'NOUN'), ('Elliott', 'NOUN'), ('191.9', '.')]\n",
      "\n",
      "Final tagging result =  [('``', '.'), ('The', 'DET'), ('disturbing', 'ADJ'), ('thing', 'NOUN'), ('about', 'ADP'), ('this', 'DET'), ('abortion', 'NOUN'), ('issue', 'NOUN'), ('is', 'VERB'), ('that', 'ADP'), ('the', 'DET'), ('debate', 'NOUN'), ('has', 'VERB'), ('become', 'VERB'), ('polarized', 'VERB'), ('*-1', 'X'), (',', '.'), ('so', 'ADV'), ('that', 'ADP'), ('no', 'DET'), ('mechanism', 'NOUN'), ('*ICH*-2', 'X'), ('exists', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('*', 'X'), ('finding', 'VERB'), ('a', 'DET'), ('middle', 'NOUN'), ('ground', 'NOUN'), ('.', '.'), ('The', 'DET'), ('judge', 'NOUN'), ('declined', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('discuss', 'VERB'), ('his', 'PRON'), ('salary', 'NOUN'), ('in', 'ADP'), ('detail', 'NOUN'), (',', '.'), ('but', 'CONJ'), ('said', 'VERB'), (':', '.'), ('``', '.'), ('I', 'PRON'), (\"'m\", 'VERB'), ('going', 'VERB'), ('*-2', 'X'), ('to', 'PRT'), ('be', 'VERB'), ('a', 'DET'), ('high-priced', 'ADJ'), ('lawyer', 'NOUN'), ('.', '.'), (\"''\", '.'), ('The', 'DET'), ('Japanese', 'ADJ'), ('retort', 'NOUN'), ('that', 'DET'), ('the', 'DET'), ('first', 'ADJ'), ('round', 'NOUN'), ('was', 'VERB'), ('too', 'ADV'), ('early', 'ADJ'), ('*', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('concessions', 'NOUN'), ('.', '.'), ('``', '.'), ('This', 'DET'), ('conforms', 'NOUN'), ('to', 'PRT'), ('the', 'DET'), ('`', '.'), ('soft', 'ADJ'), ('landing', 'NOUN'), (\"'\", 'PRT'), ('scenario', 'NOUN'), (',', '.'), (\"''\", '.'), ('said', 'VERB'), ('*T*-1', 'X'), ('Elliott', 'NOUN'), ('Platt', 'NOUN'), (',', '.'), ('an', 'DET'), ('economist', 'NOUN'), ('at', 'ADP'), ('Donaldson', 'NOUN'), (',', '.'), ('Lufkin', 'NOUN'), ('&', 'CONJ'), ('Jenrette', 'NOUN'), ('Securities', 'NOUN'), ('Corp', 'NOUN'), ('.', '.'), ('In', 'ADP'), ('its', 'PRON'), ('construction', 'NOUN'), ('spending', 'NOUN'), ('report', 'NOUN'), (',', '.'), ('the', 'DET'), ('Commerce', 'NOUN'), ('Department', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('residential', 'ADJ'), ('construction', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-50', 'X'), ('accounts', 'NOUN'), ('for', 'ADP'), ('nearly', 'ADV'), ('half', 'DET'), ('of', 'ADP'), ('all', 'DET'), ('construction', 'NOUN'), ('spending', 'NOUN'), (',', '.'), ('was', 'VERB'), ('off', 'PRT'), ('0.9', 'NUM'), ('%', 'NOUN'), ('*ICH*-3', 'X'), ('in', 'ADP'), ('September', 'NOUN'), ('to', 'PRT'), ('an', 'DET'), ('annual', 'ADJ'), ('rate', 'NOUN'), ('of', 'ADP'), ('$', '.'), ('191.9', '.'), ('billion', 'NUM'), ('*U*', 'X'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "accuracy, difference, unknown_word_tags, tagged_seq = tag_input_words(Viterbi_TransitionBasedRev, test_tagged_words, test_run_base)\n",
    "print(\"Accuracy = \", round(accuracy,2))\n",
    "print(\"\")\n",
    "print(\"Time Taken in seconds = \", round(difference,2))\n",
    "print(\"\")\n",
    "print(\"Unknown word tags = \", unknown_word_tags)\n",
    "print(\"\")\n",
    "print(\"Final tagging result = \", tagged_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viterbi plain with Rule Based Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.94\n",
      "\n",
      "Time Taken in seconds =  13.06\n",
      "\n",
      "Unknown word tags =  [('polarized', 'VERB'), ('exists', 'NOUN'), ('detail', 'NOUN'), ('retort', 'NOUN'), ('concessions', 'NOUN'), ('conforms', 'NOUN'), ('Elliott', 'NOUN'), ('191.9', 'NUM')]\n",
      "\n",
      "Final tagging result =  [('``', '.'), ('The', 'DET'), ('disturbing', 'ADJ'), ('thing', 'NOUN'), ('about', 'ADP'), ('this', 'DET'), ('abortion', 'NOUN'), ('issue', 'NOUN'), ('is', 'VERB'), ('that', 'ADP'), ('the', 'DET'), ('debate', 'NOUN'), ('has', 'VERB'), ('become', 'VERB'), ('polarized', 'VERB'), ('*-1', 'X'), (',', '.'), ('so', 'ADV'), ('that', 'ADP'), ('no', 'DET'), ('mechanism', 'NOUN'), ('*ICH*-2', 'X'), ('exists', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('*', 'X'), ('finding', 'VERB'), ('a', 'DET'), ('middle', 'NOUN'), ('ground', 'NOUN'), ('.', '.'), ('The', 'DET'), ('judge', 'NOUN'), ('declined', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('discuss', 'VERB'), ('his', 'PRON'), ('salary', 'NOUN'), ('in', 'ADP'), ('detail', 'NOUN'), (',', '.'), ('but', 'CONJ'), ('said', 'VERB'), (':', '.'), ('``', '.'), ('I', 'PRON'), (\"'m\", 'VERB'), ('going', 'VERB'), ('*-2', 'X'), ('to', 'PRT'), ('be', 'VERB'), ('a', 'DET'), ('high-priced', 'ADJ'), ('lawyer', 'NOUN'), ('.', '.'), (\"''\", '.'), ('The', 'DET'), ('Japanese', 'ADJ'), ('retort', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('first', 'ADJ'), ('round', 'NOUN'), ('was', 'VERB'), ('too', 'ADV'), ('early', 'ADJ'), ('*', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('concessions', 'NOUN'), ('.', '.'), ('``', '.'), ('This', 'DET'), ('conforms', 'NOUN'), ('to', 'PRT'), ('the', 'DET'), ('`', '.'), ('soft', 'ADJ'), ('landing', 'NOUN'), (\"'\", 'PRT'), ('scenario', 'NOUN'), (',', '.'), (\"''\", '.'), ('said', 'VERB'), ('*T*-1', 'X'), ('Elliott', 'NOUN'), ('Platt', 'NOUN'), (',', '.'), ('an', 'DET'), ('economist', 'NOUN'), ('at', 'ADP'), ('Donaldson', 'NOUN'), (',', '.'), ('Lufkin', 'NOUN'), ('&', 'CONJ'), ('Jenrette', 'NOUN'), ('Securities', 'NOUN'), ('Corp', 'NOUN'), ('.', '.'), ('In', 'ADP'), ('its', 'PRON'), ('construction', 'NOUN'), ('spending', 'NOUN'), ('report', 'NOUN'), (',', '.'), ('the', 'DET'), ('Commerce', 'NOUN'), ('Department', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('residential', 'ADJ'), ('construction', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-50', 'X'), ('accounts', 'NOUN'), ('for', 'ADP'), ('nearly', 'ADV'), ('half', 'DET'), ('of', 'ADP'), ('all', 'DET'), ('construction', 'NOUN'), ('spending', 'NOUN'), (',', '.'), ('was', 'VERB'), ('off', 'PRT'), ('0.9', 'NUM'), ('%', 'NOUN'), ('*ICH*-3', 'X'), ('in', 'ADP'), ('September', 'NOUN'), ('to', 'PRT'), ('an', 'DET'), ('annual', 'ADJ'), ('rate', 'NOUN'), ('of', 'ADP'), ('$', '.'), ('191.9', 'NUM'), ('billion', 'NUM'), ('*U*', 'X'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "accuracy, difference, unknown_word_tags, tagged_seq = tag_input_words(Viterbi_RuleBased, test_tagged_words, test_run_base)\n",
    "print(\"Accuracy = \", round(accuracy,2))\n",
    "print(\"\")\n",
    "print(\"Time Taken in seconds = \", round(difference,2))\n",
    "print(\"\")\n",
    "print(\"Unknown word tags = \", unknown_word_tags)\n",
    "print(\"\")\n",
    "print(\"Final tagging result = \", tagged_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read file of sample sentences and setup for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android is a mobile operating system developed by Google.',\n",
       " 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.',\n",
       " \"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\",\n",
       " 'Twitter is an online news and social networking service on which users post and interact with messages known as tweets.',\n",
       " 'Before entering politics, Donald Trump was a domineering businessman and a television personality.',\n",
       " 'The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.',\n",
       " 'This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.',\n",
       " 'Show me the cheapest round trips from Dallas to Atlanta',\n",
       " 'I would like to see flights from Denver to Philadelphia.',\n",
       " 'Show me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.',\n",
       " 'NASA invited social media users to experience the launch of ICESAT-2 Satellite.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Test_sentences.txt', 'r') as f:\n",
    "    sample_test_sentences = f.read().splitlines()\n",
    "sample_test_sentences = list(filter(None, sample_test_sentences))\n",
    "sample_test_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle puncutations and apostrophe s\n",
    "Parse all the sentences into words along with special cases like full-stop, apostrophe s, comma as a different words.\n",
    "Put a space before punctuations and 's so that they get split as different words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Android',\n",
       "  'is',\n",
       "  'a',\n",
       "  'mobile',\n",
       "  'operating',\n",
       "  'system',\n",
       "  'developed',\n",
       "  'by',\n",
       "  'Google',\n",
       "  '.'],\n",
       " ['Android',\n",
       "  'has',\n",
       "  'been',\n",
       "  'the',\n",
       "  'best-selling',\n",
       "  'OS',\n",
       "  'worldwide',\n",
       "  'on',\n",
       "  'smartphones',\n",
       "  'since',\n",
       "  '2011',\n",
       "  'and',\n",
       "  'on',\n",
       "  'tablets',\n",
       "  'since',\n",
       "  '2013',\n",
       "  '.'],\n",
       " ['Google',\n",
       "  'and',\n",
       "  'Twitter',\n",
       "  'made',\n",
       "  'a',\n",
       "  'deal',\n",
       "  'in',\n",
       "  '2015',\n",
       "  'that',\n",
       "  'gave',\n",
       "  'Google',\n",
       "  'access',\n",
       "  'to',\n",
       "  'Twitter',\n",
       "  \"'s\",\n",
       "  'firehose',\n",
       "  '.'],\n",
       " ['Twitter',\n",
       "  'is',\n",
       "  'an',\n",
       "  'online',\n",
       "  'news',\n",
       "  'and',\n",
       "  'social',\n",
       "  'networking',\n",
       "  'service',\n",
       "  'on',\n",
       "  'which',\n",
       "  'users',\n",
       "  'post',\n",
       "  'and',\n",
       "  'interact',\n",
       "  'with',\n",
       "  'messages',\n",
       "  'known',\n",
       "  'as',\n",
       "  'tweets',\n",
       "  '.'],\n",
       " ['Before',\n",
       "  'entering',\n",
       "  'politics',\n",
       "  ',',\n",
       "  'Donald',\n",
       "  'Trump',\n",
       "  'was',\n",
       "  'a',\n",
       "  'domineering',\n",
       "  'businessman',\n",
       "  'and',\n",
       "  'a',\n",
       "  'television',\n",
       "  'personality',\n",
       "  '.'],\n",
       " ['The',\n",
       "  '2018',\n",
       "  'FIFA',\n",
       "  'World',\n",
       "  'Cup',\n",
       "  'is',\n",
       "  'the',\n",
       "  '21st',\n",
       "  'FIFA',\n",
       "  'World',\n",
       "  'Cup',\n",
       "  ',',\n",
       "  'an',\n",
       "  'international',\n",
       "  'football',\n",
       "  'tournament',\n",
       "  'contested',\n",
       "  'once',\n",
       "  'every',\n",
       "  'four',\n",
       "  'years',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'is',\n",
       "  'the',\n",
       "  'first',\n",
       "  'World',\n",
       "  'Cup',\n",
       "  'to',\n",
       "  'be',\n",
       "  'held',\n",
       "  'in',\n",
       "  'Eastern',\n",
       "  'Europe',\n",
       "  'and',\n",
       "  'the',\n",
       "  '11th',\n",
       "  'time',\n",
       "  'that',\n",
       "  'it',\n",
       "  'has',\n",
       "  'been',\n",
       "  'held',\n",
       "  'in',\n",
       "  'Europe',\n",
       "  '.'],\n",
       " ['Show',\n",
       "  'me',\n",
       "  'the',\n",
       "  'cheapest',\n",
       "  'round',\n",
       "  'trips',\n",
       "  'from',\n",
       "  'Dallas',\n",
       "  'to',\n",
       "  'Atlanta'],\n",
       " ['I',\n",
       "  'would',\n",
       "  'like',\n",
       "  'to',\n",
       "  'see',\n",
       "  'flights',\n",
       "  'from',\n",
       "  'Denver',\n",
       "  'to',\n",
       "  'Philadelphia',\n",
       "  '.'],\n",
       " ['Show',\n",
       "  'me',\n",
       "  'the',\n",
       "  'price',\n",
       "  'of',\n",
       "  'the',\n",
       "  'flights',\n",
       "  'leaving',\n",
       "  'Atlanta',\n",
       "  'at',\n",
       "  'about',\n",
       "  '3',\n",
       "  'in',\n",
       "  'the',\n",
       "  'afternoon',\n",
       "  'and',\n",
       "  'arriving',\n",
       "  'in',\n",
       "  'San',\n",
       "  'Francisco',\n",
       "  '.'],\n",
       " ['NASA',\n",
       "  'invited',\n",
       "  'social',\n",
       "  'media',\n",
       "  'users',\n",
       "  'to',\n",
       "  'experience',\n",
       "  'the',\n",
       "  'launch',\n",
       "  'of',\n",
       "  'ICESAT-2',\n",
       "  'Satellite',\n",
       "  '.']]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sent_list_words = []\n",
    "for sent in sample_test_sentences:\n",
    "    sent = sent.replace('.', ' .')\n",
    "    sent = sent.replace('\\'s', ' \\'s')\n",
    "    sent = sent.replace(',', ' ,')\n",
    "    sent_words = sent.split()\n",
    "    sample_sent_list_words.append(sent_words)\n",
    "    \n",
    "sample_sent_list_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sent_test(test_sentence):\n",
    "    test_words = [word for word in test_sentence]\n",
    "    print(\"Test sentence = \", test_sentence)\n",
    "    print(\"\")\n",
    "    accuracy, difference, vanilla_unknown_word_tags, vanilla_tagged_seq = tag_input_words(Viterbi_Vanilla, test_words)\n",
    "    print(\"Vanilla Unknown word tags = \", vanilla_unknown_word_tags)\n",
    "    print(\"\")\n",
    "    print(\"Vanilla Final Tagging Result = \", vanilla_tagged_seq)\n",
    "    print(\"\")\n",
    "    accuracy, difference, trans_unknown_word_tags, trans_tagged_seq = tag_input_words(Viterbi_TransitionBased, test_words)\n",
    "    print(\"Method 1:Transition Based Unknown word tags = \", trans_unknown_word_tags)\n",
    "    print(\"\")\n",
    "    print(\"Method 1:Transition Based Final Tagging Result = \", trans_tagged_seq)\n",
    "    print(\"\")\n",
    "    accuracy, difference, revtrans_unknown_word_tags, revtrans_tagged_seq = tag_input_words(Viterbi_TransitionBasedRev, test_words)\n",
    "    print(\"Method 2:Rev Transition Based Unknown word tags = \", revtrans_unknown_word_tags)\n",
    "    print(\"\")\n",
    "    print(\"Method 2:Rev Transition Based Final Tagging Result = \", revtrans_tagged_seq)\n",
    "    print(\"\")\n",
    "    accuracy, difference, rule_unknown_word_tags, rule_tagged_seq = tag_input_words(Viterbi_RuleBased, test_words)\n",
    "    print(\"Method 3:Rule Based Unknown word tags = \", rule_unknown_word_tags)\n",
    "    print(\"\")\n",
    "    print(\"Method 3:Rule Based Final Tagging Result = \", revtrans_tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sentence =  ['Android', 'has', 'been', 'the', 'best-selling', 'OS', 'worldwide', 'on', 'smartphones', 'since', '2011', 'and', 'on', 'tablets', 'since', '2013', '.']\n",
      "\n",
      "Vanilla Unknown word tags =  [('Android', '.'), ('OS', '.'), ('worldwide', '.'), ('smartphones', '.'), ('2011', '.'), ('tablets', '.'), ('2013', '.')]\n",
      "\n",
      "Vanilla Final Tagging Result =  [('Android', '.'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', '.'), ('worldwide', '.'), ('on', 'ADP'), ('smartphones', '.'), ('since', 'ADP'), ('2011', '.'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', '.'), ('since', 'ADP'), ('2013', '.'), ('.', '.')]\n",
      "\n",
      "Method 1:Transition Based Unknown word tags =  [('Android', 'NOUN'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('smartphones', 'DET'), ('2011', 'DET'), ('tablets', 'DET'), ('2013', 'DET')]\n",
      "\n",
      "Method 1:Transition Based Final Tagging Result =  [('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'DET'), ('since', 'ADP'), ('2011', 'DET'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'DET'), ('since', 'ADP'), ('2013', 'DET'), ('.', '.')]\n",
      "\n",
      "Method 2:Rev Transition Based Unknown word tags =  [('Android', 'NOUN'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('smartphones', 'NOUN'), ('2011', 'NOUN'), ('tablets', 'NOUN'), ('2013', 'NOUN')]\n",
      "\n",
      "Method 2:Rev Transition Based Final Tagging Result =  [('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NOUN'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NOUN'), ('.', '.')]\n",
      "\n",
      "Method 3:Rule Based Unknown word tags =  [('Android', 'NOUN'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('smartphones', 'NOUN'), ('2011', 'NUM'), ('tablets', 'NOUN'), ('2013', 'NUM')]\n",
      "\n",
      "Method 3:Rule Based Final Tagging Result =  [('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NOUN'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NOUN'), ('.', '.')]\n",
      "======================================================================================\n",
      "Test sentence =  ['The', '2018', 'FIFA', 'World', 'Cup', 'is', 'the', '21st', 'FIFA', 'World', 'Cup', ',', 'an', 'international', 'football', 'tournament', 'contested', 'once', 'every', 'four', 'years', '.']\n",
      "\n",
      "Vanilla Unknown word tags =  [('2018', '.'), ('FIFA', '.'), ('Cup', '.'), ('21st', '.'), ('FIFA', '.'), ('Cup', '.'), ('tournament', '.'), ('contested', '.')]\n",
      "\n",
      "Vanilla Final Tagging Result =  [('The', 'DET'), ('2018', '.'), ('FIFA', '.'), ('World', 'NOUN'), ('Cup', '.'), ('is', 'VERB'), ('the', 'DET'), ('21st', '.'), ('FIFA', '.'), ('World', 'NOUN'), ('Cup', '.'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', '.'), ('contested', '.'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]\n",
      "\n",
      "Method 1:Transition Based Unknown word tags =  [('2018', 'NOUN'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'NOUN')]\n",
      "\n",
      "Method 1:Transition Based Final Tagging Result =  [('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'NOUN'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]\n",
      "\n",
      "Method 2:Rev Transition Based Unknown word tags =  [('2018', 'NOUN'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB')]\n",
      "\n",
      "Method 2:Rev Transition Based Final Tagging Result =  [('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]\n",
      "\n",
      "Method 3:Rule Based Unknown word tags =  [('2018', 'NUM'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('21st', 'ADJ'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB')]\n",
      "\n",
      "Method 3:Rule Based Final Tagging Result =  [('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]\n",
      "======================================================================================\n",
      "Test sentence =  ['NASA', 'invited', 'social', 'media', 'users', 'to', 'experience', 'the', 'launch', 'of', 'ICESAT-2', 'Satellite', '.']\n",
      "\n",
      "Vanilla Unknown word tags =  [('NASA', '.'), ('invited', '.'), ('ICESAT-2', '.'), ('Satellite', '.')]\n",
      "\n",
      "Vanilla Final Tagging Result =  [('NASA', '.'), ('invited', '.'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', '.'), ('Satellite', '.'), ('.', '.')]\n",
      "\n",
      "Method 1:Transition Based Unknown word tags =  [('NASA', 'NOUN'), ('invited', 'NOUN'), ('ICESAT-2', 'DET'), ('Satellite', 'NOUN')]\n",
      "\n",
      "Method 1:Transition Based Final Tagging Result =  [('NASA', 'NOUN'), ('invited', 'NOUN'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'DET'), ('Satellite', 'NOUN'), ('.', '.')]\n",
      "\n",
      "Method 2:Rev Transition Based Unknown word tags =  [('NASA', 'NOUN'), ('invited', 'DET'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN')]\n",
      "\n",
      "Method 2:Rev Transition Based Final Tagging Result =  [('NASA', 'NOUN'), ('invited', 'DET'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')]\n",
      "\n",
      "Method 3:Rule Based Unknown word tags =  [('NASA', 'NOUN'), ('invited', 'VERB'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN')]\n",
      "\n",
      "Method 3:Rule Based Final Tagging Result =  [('NASA', 'NOUN'), ('invited', 'DET'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sample_sent_test(sample_sent_list_words[1])\n",
    "print('======================================================================================')\n",
    "sample_sent_test(sample_sent_list_words[5])\n",
    "print('======================================================================================')\n",
    "sample_sent_test(sample_sent_list_words[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data tag set testing with accuracy\n",
    "\n",
    "The sentences from the \"Sample test sentences\" have been taken and tagged, so that accuracy can be calculated along with the pointing out the correctly tagged words because of the modified Viterbi algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_tagged_words = [\n",
    " [('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.')],\n",
    " [('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NUM'), ('.', '.')],\n",
    " [('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NUM'), ('that', 'DET'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'NOUN'), ('\\'s', 'PRT'), ('firehose', 'NOUN'), ('.', '.')],\n",
    " [('Twitter', 'NOUN'), ('is', 'VERB'), ('an', 'DET'), ('online', 'ADJ'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'VERB'), ('and', 'CONJ'), ('interact', 'VERB'), ('with', 'ADP'), ('messages', 'NOUN'), ('known', 'VERB'), ('as', 'ADP'), ('tweets', 'NOUN'), ('.', '.')],\n",
    " [('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'ADJ'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.')],\n",
    " [('The', 'DET'), ('2018', 'NUM'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'ADJ'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')],\n",
    " [('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.')],\n",
    " [('Show', 'VERB'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'NOUN'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN')],\n",
    " [('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.')],\n",
    " [('Show', 'VERB'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'VERB'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.')],\n",
    " [('NASA', 'NOUN'), ('invited', 'VERB'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'VERB'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test_run_base = sample_tagged_words[0:3]\n",
    "test_run = []\n",
    "test_run.append(sample_tagged_words[1])\n",
    "test_run.append(sample_tagged_words[5])\n",
    "test_run.append(sample_tagged_words[10])\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for tup in test_run_base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.62\n",
      "\n",
      "Time Taken in seconds =  4.92\n",
      "\n",
      "Unknown word tags =  [('Android', '.'), ('OS', '.'), ('worldwide', '.'), ('smartphones', '.'), ('2011', '.'), ('tablets', '.'), ('2013', '.'), ('2018', '.'), ('FIFA', '.'), ('Cup', '.'), ('21st', '.'), ('FIFA', '.'), ('Cup', '.'), ('tournament', '.'), ('contested', '.'), ('NASA', '.'), ('invited', '.'), ('ICESAT-2', '.'), ('Satellite', '.')]\n",
      "\n",
      "Final tagging result =  [('Android', '.'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', '.'), ('worldwide', '.'), ('on', 'ADP'), ('smartphones', '.'), ('since', 'ADP'), ('2011', '.'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', '.'), ('since', 'ADP'), ('2013', '.'), ('.', '.'), ('The', 'DET'), ('2018', '.'), ('FIFA', '.'), ('World', 'NOUN'), ('Cup', '.'), ('is', 'VERB'), ('the', 'DET'), ('21st', '.'), ('FIFA', '.'), ('World', 'NOUN'), ('Cup', '.'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', '.'), ('contested', '.'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('NASA', '.'), ('invited', '.'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', '.'), ('Satellite', '.'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "accuracy, difference, unknown_word_tags, tagged_seq = tag_input_words(Viterbi_Vanilla, test_tagged_words, test_run_base)\n",
    "print(\"Accuracy = \", round(accuracy,2))\n",
    "print(\"\")\n",
    "print(\"Time Taken in seconds = \", round(difference,2))\n",
    "print(\"\")\n",
    "print(\"Unknown word tags = \", unknown_word_tags)\n",
    "print(\"\")\n",
    "print(\"Final tagging result = \", tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.81\n",
      "\n",
      "Time Taken in seconds =  4.79\n",
      "\n",
      "Unknown word tags =  [('Android', 'NOUN'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('smartphones', 'DET'), ('2011', 'DET'), ('tablets', 'DET'), ('2013', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'NOUN'), ('NASA', 'NOUN'), ('invited', 'NOUN'), ('ICESAT-2', 'DET'), ('Satellite', 'NOUN')]\n",
      "\n",
      "Final tagging result =  [('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'DET'), ('since', 'ADP'), ('2011', 'DET'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'DET'), ('since', 'ADP'), ('2013', 'DET'), ('.', '.'), ('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'NOUN'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('NASA', 'NOUN'), ('invited', 'NOUN'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'DET'), ('Satellite', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "accuracy, difference, unknown_word_tags, tagged_seq = tag_input_words(Viterbi_TransitionBased, test_tagged_words, test_run_base)\n",
    "print(\"Accuracy = \", round(accuracy,2))\n",
    "print(\"\")\n",
    "print(\"Time Taken in seconds = \", round(difference,2))\n",
    "print(\"\")\n",
    "print(\"Unknown word tags = \", unknown_word_tags)\n",
    "print(\"\")\n",
    "print(\"Final tagging result = \", tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.88\n",
      "\n",
      "Time Taken in seconds =  4.87\n",
      "\n",
      "Unknown word tags =  [('Android', 'NOUN'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('smartphones', 'NOUN'), ('2011', 'NOUN'), ('tablets', 'NOUN'), ('2013', 'NOUN'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('NASA', 'NOUN'), ('invited', 'DET'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN')]\n",
      "\n",
      "Final tagging result =  [('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NOUN'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NOUN'), ('.', '.'), ('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('NASA', 'NOUN'), ('invited', 'DET'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "accuracy, difference, unknown_word_tags, tagged_seq = tag_input_words(Viterbi_TransitionBasedRev, test_tagged_words, test_run_base)\n",
    "print(\"Accuracy = \", round(accuracy,2))\n",
    "print(\"\")\n",
    "print(\"Time Taken in seconds = \", round(difference,2))\n",
    "print(\"\")\n",
    "print(\"Unknown word tags = \", unknown_word_tags)\n",
    "print(\"\")\n",
    "print(\"Final tagging result = \", tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.98\n",
      "\n",
      "Time Taken in seconds =  4.71\n",
      "\n",
      "Unknown word tags =  [('Android', 'NOUN'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('smartphones', 'NOUN'), ('2011', 'NUM'), ('tablets', 'NOUN'), ('2013', 'NUM'), ('2018', 'NUM'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('21st', 'ADJ'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('NASA', 'NOUN'), ('invited', 'VERB'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN')]\n",
      "\n",
      "Final tagging result =  [('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NUM'), ('.', '.'), ('The', 'DET'), ('2018', 'NUM'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'ADJ'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('NASA', 'NOUN'), ('invited', 'VERB'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "accuracy, difference, unknown_word_tags, tagged_seq = tag_input_words(Viterbi_RuleBased, test_tagged_words, test_run_base)\n",
    "print(\"Accuracy = \", round(accuracy,2))\n",
    "print(\"\")\n",
    "print(\"Time Taken in seconds = \", round(difference,2))\n",
    "print(\"\")\n",
    "print(\"Unknown word tags = \", unknown_word_tags)\n",
    "print(\"\")\n",
    "print(\"Final tagging result = \", tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "#### Accuracies for chosen test-set\n",
    "<table align=left width=100%>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Algorithm</th><th>Accuracy</th></tr>\n",
    "</thead>\n",
    "<tr><td>Vanilla Viterbi</td><td>89%</td></tr>\n",
    "<tr><td>Vanilla Viterbi with max of Transition Based probability tagging for unknown words</td><td>91%</td></tr>\n",
    "<tr><td>Vanilla Viterbi with max of Transition and Reverse Transition Based probability tagging for unknown words</td><td>92%</td></tr>\n",
    "<tr><td>Vanilla Viterbi with Rule based tagging for unknown words</td><td>94%</td></tr>\n",
    "</table>\n",
    "<hr/>\n",
    "<p>&nbsp;</p>\n",
    "<p>\n",
    "<h4>Example 3 cases of correction of POS tags for unknown words</h4>\n",
    "<table align=left width=100%>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Algorithm</th><th>Unknown word tags</th><th>Final tagging result</th></tr>\n",
    "</thead>\n",
    "<tr><td colspan=3><b>Test Sentence : Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.</b></td>\n",
    "<tr><td>Vanilla Viterbi</td>\n",
    "<td>[('Android', '.'), ('OS', '.'), ('worldwide', '.'), ('smartphones', '.'), ('2011', '.'), ('tablets', '.'), ('2013', '.')]</td>\n",
    "<td>[('Android', '.'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', '.'), ('worldwide', '.'), ('on', 'ADP'), ('smartphones', '.'), ('since', 'ADP'), ('2011', '.'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', '.'), ('since', 'ADP'), ('2013', '.'), ('.', '.')]</td>\n",
    "</tr>\n",
    "<tr><td>Vanilla Viterbi with max of Transition Based probability tagging for unknown words</td>\n",
    "<td>[('Android', '<font color=green><b>NOUN</b></font>'), ('OS', '<font color=green><b>NOUN</b></font>'), ('worldwide', '<font color=green><b>NOUN</b></font>'), ('smartphones', '<font color=green><b>DET</b></font>'), ('2011', '<font color=green><b>DET</b></font>'), ('tablets', '<font color=green><b>DET</b></font>'), ('2013', '<font color=green><b>DET</b></font>')]</td>\n",
    "<td>[('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'DET'), ('since', 'ADP'), ('2011', 'DET'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'DET'), ('since', 'ADP'), ('2013', 'DET'), ('.', '.')]</td></tr>\n",
    "<tr><td>Vanilla Viterbi with max of Transition and Reverse Transition Based probability tagging for unknown words</td><td>[('Android', 'NOUN'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('smartphones', '<font color=green><b>NOUN</b></font>'), ('2011', '<font color=green><b>NOUN</b></font>'), ('tablets', '<font color=green><b>NOUN</b></font>'), ('2013', '<font color=green><b>NOUN</b></font>')]</td>\n",
    "<td>[('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NOUN'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NOUN'), ('.', '.')]</td></tr>\n",
    "<tr><td>Vanilla Viterbi with Rule based tagging for unknown words</td>\n",
    "<td>[('Android', 'NOUN'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('smartphones', 'NOUN'), ('2011', '<font color=green><b>NUM</b></font>'), ('tablets', 'NOUN'), ('2013', '<font color=green><b>NUM</b></font>')]</td>\n",
    "<td>[('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NOUN'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NOUN'), ('.', '.')]</td></tr>\n",
    "\n",
    "<tr><td colspan=3><b>Test sentence : The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.</b></td><tr>\n",
    "<tr><td>Vanilla Viterbi</td><td>[('2018', '.'), ('FIFA', '.'), ('Cup', '.'), ('21st', '.'), ('FIFA', '.'), ('Cup', '.'), ('tournament', '.'), ('contested', '.')]</td>\n",
    "<td>[('The', 'DET'), ('2018', '.'), ('FIFA', '.'), ('World', 'NOUN'), ('Cup', '.'), ('is', 'VERB'), ('the', 'DET'), ('21st', '.'), ('FIFA', '.'), ('World', 'NOUN'), ('Cup', '.'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', '.'), ('contested', '.'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]</td><tr>\n",
    "<tr><td>Vanilla Viterbi with max of Transition Based probability tagging for unknown words</td>\n",
    "<td>[('2018', '<font color=green><b>NOUN</b></font>'), ('FIFA', '<font color=green><b>NOUN</b></font>'), ('Cup', '<font color=green><b>NOUN</b></font>), ('21st', '<font color=green><b>NOUN</b></font>'), ('FIFA', '<font color=green><b>NOUN</b></font>'), ('Cup', '<font color=green><b>NOUN</b></font>'), ('tournament', '<font color=green><b>NOUN</b></font>'), ('contested', '<font color=green><b>NOUN</b></font>')]</td>\n",
    "<td>[('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'NOUN'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]</td><tr>\n",
    "<tr><td>Vanilla Viterbi with max of Transition and Reverse Transition Based probability tagging for unknown words</td><td>[('2018', 'NOUN'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('tournament', 'NOUN'), ('contested', '<font color=green><b>VERB</b></font>')]</td>\n",
    "<td>[('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]</td><tr>\n",
    "<tr><td>Vanilla Viterbi with Rule based tagging for unknown words</td>\n",
    "<td>[('2018', '<font color=green><b>NUM</b></font>'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('21st', '<font color=green><b>ADJ</b></font>'), ('FIFA', 'NOUN'), ('Cup', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB')]</td>\n",
    "<td>[('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]</td><tr>\n",
    "\n",
    "<tr><td colspan=3><b>Test sentence : NASA invited social media users to experience the launch of ICESAT-2 Satellite.</b></td><tr>\n",
    "<tr><td>Vanilla Viterbi</td>\n",
    "<td>[('NASA', '.'), ('invited', '.'), ('ICESAT-2', '.'), ('Satellite', '.')]</td>\n",
    "<td>[('NASA', '.'), ('invited', '.'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', '.'), ('Satellite', '.'), ('.', '.')]</td><tr>\n",
    "<tr><td>Vanilla Viterbi with max of Transition Based probability tagging for unknown words</td>\n",
    "<td>[('NASA', '<font color=green><b>NOUN</b></font>'), ('invited', '<font color=green><b>NOUN</b></font>'), ('ICESAT-2', '<font color=green><b>DET</b></font>'), ('Satellite', '<font color=green><b>NOUN</b></font>')]</td>\n",
    "<td>[('NASA', 'NOUN'), ('invited', 'NOUN'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'DET'), ('Satellite', 'NOUN'), ('.', '.')]</td><tr>\n",
    "<tr><td>Vanilla Viterbi with max of Transition and Reverse Transition Based probability tagging for unknown words</td><td>[('NASA', 'NOUN'), ('invited', '<font color=green><b>DET</b></font>'), ('ICESAT-2', '<font color=green><b>NOUN</b></font>'), ('Satellite', 'NOUN')]</td>\n",
    "<td>[('NASA', 'NOUN'), ('invited', 'DET'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')]</td><tr>\n",
    "<tr><td>Vanilla Viterbi with Rule based tagging for unknown words</td><td>[('NASA', 'NOUN'), ('invited', '<font color=green><b>VERB</b></font>'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN')]</td>\n",
    "<td>[('NASA', 'NOUN'), ('invited', 'DET'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')]</td><tr>\n",
    "</table>\n",
    "<hr/>\n",
    "<p>&nbsp;</p>\n",
    "<h4>Accuracies for the same Example 3 cases of correction of POS tags for unknown words</h4>\n",
    "<table align=left width=100%>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Algorithm</th><th>Accuracy</th></tr>\n",
    "</thead>\n",
    "<tr><td>Vanilla Viterbi</td><td>62%</td></tr>\n",
    "<tr><td>Vanilla Viterbi with max of Transition Based probability tagging for unknown words</td><td>81%</td></tr>\n",
    "<tr><td>Vanilla Viterbi with max of Transition and Reverse Transition Based probability tagging for unknown words</td><td>88%</td></tr>\n",
    "<tr><td>Vanilla Viterbi with Rule based tagging for unknown words</td><td>98%</td></tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
